import requests
from bs4 import BeautifulSoup
import time
import pandas as pd
import re
import datetime
import random
import glob
def get_owner_car_price():
    car_data = []
    catch_link = set()
    headers = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"}
    page = 1
    while True:
        url = f"https://www.kijiji.ca/b-cars-trucks/red-deer/page-{page}/c174l1700136?for-sale-by=ownr&view=list"
        req = requests.get(url,headers=headers)
        if req.status_code != 200:
            break
        soup = BeautifulSoup(req.text,"html.parser")
        new_data = 0
        car_card = soup.find_all("section",attrs={"data-testid":re.compile("listing-card")})
        if len(car_card) <= 0:
            print(f"NO CARS HERE!")
            break
        else:
            print(f"find{len(car_card)}cars")
        for car in car_card:
            try:
                car_name = car.find("a",attrs={"data-testid":re.compile("listing-link")})
                if not car_name:
                    continue
                car_link = car_name['href']
                if car_link in catch_link:
                    continue
                catch_link.add(car_link)
                new_data += 1
                car_title = car_name.text
                card_text = car.get_text(separator=" ", strip=True)
                mileage_match = re.search(r"(\d[\d,]*\s*km)", card_text, re.IGNORECASE)
                if mileage_match:
                    drive_distance = mileage_match.group(1)
                else:
                    drive_distance = "N/A"
                car_price = car.find("p",attrs={"data-testid":re.compile("listing-price")})
                if car_price:
                    p_price = car_price.text
                    if any(i.isdigit() for i in p_price):
                        price = float(p_price.replace("$","").replace(",","").strip())
                        car_data.append({"Car title":car_title,"Drive distance":drive_distance,"Price":price,"Link":car_link})
                        print(f"GET IT!{car_title}:{price}")
            except Exception as e:
                print(f"Something wrong in the try:{e}")
                continue
        if len(car_card) > 0 and new_data == 0:
            print(f"First page again! break!")
            break
        time.sleep(random.uniform(5, 10))
        page += 1
        if page >100:
            break
    return car_data
def clean_car_data(df):
    valid_brands = ["ford", "chev", "gmc", "dodge", "ram", "toyota", "honda", "nissan", "mazda", 
    "vw", "volkswagen", "bmw", "mercedes", "audi", "kia", "hyundai", "jeep", 
    "subaru", "lexus", "acura", "infiniti", "cadillac", "buick", "lincoln", 
    "chrysler", "pontiac", "saturn", "volvo", "mitsubishi", "suzuki", "mini", "tesla"]
    blacklist = ["part out", "parting out", "parts only", "wrecking", "scrap", 
    "tires", "rims", "wheels", "wanted", "buying", "service", "cash","parts"]
    print(f"clean {len(df)} data")
    cleaned_data = []
    for index, row in df.iterrows():
        title = str(row['Car title']).strip()
        price = row['Price']
        if any(fake in title.lower() for fake in blacklist):
            continue
        if price < 500:
            continue
        has_year = re.search(r'\b(19|20)\d{2}\b', title)
        has_brand = any(brand in title.lower() for brand in valid_brands)
        if re.match(r'^(19|20)\d{2}\b', title):
            cleaned_data.append(row)
        elif has_year and has_brand:
            cleaned_data.append(row)
        else:
            print(f"the {title} is not a car")
            pass
    return pd.DataFrame(cleaned_data)
def analysis_data(df_today,today):
    files = sorted(glob.glob("red_deer_*_owner_car_price.csv"))
    if len(files) < 2:
        print(f"not enough data")
        return
    prev_file = files[-2]
    print(f"{prev_file} into the program")
    df_prev = pd.read_csv(prev_file)
    new_cars = df_today[~df_today["Link"].isin(df_prev["Link"])]
    if not new_cars.empty:
        new_filename = f"red_deer_{today}_new_car_update.csv"
        new_cols=["Car title","Drive distance","Price","Link"]
        new_cars[new_cols].to_csv(new_filename, index=False, encoding="utf-8-sig")
        print(f"find {len(new_cars)} new cars")
    else:
        print(f"not have new cars today")
if __name__ == "__main__":
    print(f"Car Price Check ON!") 
    data = get_owner_car_price()
    if data:
        today = datetime.datetime.now().strftime("%Y_%m_%d")
        filename = f"red_deer_{today}_owner_car_price.csv"
        df_raw = pd.DataFrame(data)
        df = clean_car_data(df_raw)
        df_sorted = df.sort_values(by="Price")
        print(f"find {len(df)} cars")
        print(df_sorted)
        df_sorted.to_csv(filename, index=False, encoding="utf-8-sig")
        print(f"Today owner car price save as {filename}")
        analysis_data(df_sorted,today)
        print(f"data analysis compelete")
    else:
        print(f"FUCK! NO NEW CAR DATA TODAY!")